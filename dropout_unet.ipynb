{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgW_sm8ChG4M"
   },
   "source": [
    "This code implements an all dropout UNET model in Keras. The architecture was inspired by U-Net: Convolutional Networks for Biomedical Image Segmentation base paper. The original dataset is from the RSNA Pneumonia challenge and can be found in the folder data/membrane/train. The test data will be in the 'test' folder and the genrated masks will be in the 'results' folder. The data for training contains 546 images with their respective masks, which are far not enough to feed a deep learning neural network. I have augmented the data using ImageDataGenerator. This deep neural network is implemented with Keras functional API, which makes it extremely easy to experiment with different interesting architectures. The output from the network is a 224 * 224 mask that is learned from the training data. Sigmoid activation function makes sure that mask pixels are in [0, 1] range. The model is trained for 200 epochs with 2000 steps per epoch. After 200 epochs, the calculated accuracy is about 0.98. The loss function for the training is basically just a binary crossentropy. This notebook depends on the following libraries: Tensorflow Keras >= 1.0. Also, this code should be compatible with Python versions 2.7-3.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GykzUkwRij6u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajaramans2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load libraries\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "#from model import *\n",
    "#from data import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "try:\n",
    "    from itertools import izip as zip\n",
    "except ImportError: # will be 3.x series\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rajaramans2\\\\codes\\\\UNET'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nk8UUvGCiugO"
   },
   "source": [
    "Define the UNET model. This is an all dropout model as suggested in the base paper. The dropout ratio is fixed to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYNn4zRQizlO"
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (224,224,1)): \n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    drop1 = Dropout(0.1)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(drop1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    drop2 = Dropout(0.1)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(drop2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    drop3 = Dropout(0.1)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(drop3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.1)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.1)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = Add()([conv4,up6])\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    drop6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop6))\n",
    "    merge7 = Add()([conv3,up7])\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    drop7 = Dropout(0.1)(conv7)\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop7))\n",
    "    merge8 = Add()([conv2,up8])\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    drop8 = Dropout(0.1)(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop8))\n",
    "    merge9 = Add()([conv1,up9])\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    drop9 = Dropout(0.1)(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-5), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qiv99YV9i6j4"
   },
   "source": [
    "Define the data format and the functions to train and test with the data using image generators. Make sure to use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same if you want to visualize the results of generator, set save_to_dir = \"your path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rdxrszdki-_Q"
   },
   "outputs": [],
   "source": [
    "Sky = [128,128,128]\n",
    "Building = [128,0,0]\n",
    "Pole = [192,192,128]\n",
    "Road = [128,64,128]\n",
    "Pavement = [60,40,222]\n",
    "Tree = [128,128,0]\n",
    "SignSymbol = [192,128,128]\n",
    "Fence = [64,64,128]\n",
    "Car = [64,0,128]\n",
    "Pedestrian = [64,64,0]\n",
    "Bicyclist = [0,128,192]\n",
    "Unlabelled = [0,0,0]\n",
    "\n",
    "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n",
    "                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "\n",
    "\n",
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (224,224),seed = 1): \n",
    "\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "\n",
    "def testGenerator(test_path,target_size = (224,224),flag_multi_class = False,as_gray = True): \n",
    "    for filename in os.listdir(test_path):\n",
    "        img = io.imread(os.path.join(test_path,filename),as_gray = as_gray) \n",
    "        img = img / 255.\n",
    "        img = trans.resize(img,target_size)\n",
    "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "\n",
    "def saveResult(save_path,npyfile,test_path, flag_multi_class = False,num_class = 2):\n",
    "    file_names = os.listdir(test_path)\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,file_names[i]),img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSH-V_uljkQ7"
   },
   "source": [
    "Its time to train and test the Dropout_UNET model.\n",
    "\n",
    "Data augmentation:\n",
    "\n",
    "In deep learning tasks, a lot of data is need to train DNN model, when the dataset is not big enough, data augmentation should be applied. Keras.preprocessing.image.ImageDataGenerator is a data generator, which can feed the DNN with data like : (data,label), it can also do data augmentation at the same time. It is very convenient for us to use keras.preprocessing.image.ImageDataGenerator to do data augmentation by implement image rotation, shift, rescale and so on. See keras documentation for detail. For image segmentation tasks, the image and mask must be transformed together!! You can define your data generator and visualize your data augmentation result by setyting save_to_dir = \"your path\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSCX6yYcjn67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 224, 224, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 112, 112, 128 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 128)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 56, 56, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 28, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 1024) 0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 512)  0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 512)  2359808     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 28, 28, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 512)  0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 56, 56, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 56, 56, 256)  590080      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 56, 56, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 56, 56, 256)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 256 0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 112, 112, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 112, 112, 128 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 112, 112, 128 147584      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 112, 112, 128 147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 112, 112, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 128 0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 224, 224, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 224, 224, 64) 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 224, 224, 64) 36928       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 224, 224, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 224, 224, 64) 0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 224, 224, 2)  1154        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 224, 224, 1)  3           conv2d_23[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,898,245\n",
      "Trainable params: 27,898,245\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Found 546 images belonging to 1 classes.\n",
      "Found 546 images belonging to 1 classes.\n",
      " 121/2000 [>.............................] - ETA: 6:20 - loss: 0.4248 - acc: 0.7578"
     ]
    }
   ],
   "source": [
    "test_path = \"data/membrane/test\"\n",
    "save_path = \"data/membrane/result\"\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "myGene = trainGenerator(2,'data/membrane/train','image','label',data_gen_args,save_to_dir = None) #batch size = 2 here\n",
    "\n",
    "\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('dropout_unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene,steps_per_epoch=2000,epochs=200, verbose=1, callbacks=[model_checkpoint]) \n",
    "testGene = testGenerator(test_path)\n",
    "model = unet()\n",
    "model.load_weights(\"dropout_unet.hdf5\")\n",
    "results = model.predict_generator(testGene,7714,verbose=1, workers=1, use_multiprocessing=False) \n",
    "#steps per epoch is the no. of samples in test image, here it is 7714.\n",
    "saveResult(save_path, results, test_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dropout_unet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
